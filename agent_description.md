### Pristine Agent

The Pristine Agent is an autonomous AI agent designed to manage GitHub repository issues. It continuously monitors a designated repository for changes, intelligently analyzes the context using a Large Language Model (LLM), and performs actions to maintain the issue tracker.

#### Functionality

*   **Issue Management**: Creates, retrieves, updates (title, body, labels), comments on, and closes GitHub issues. It aims to detect and manage issues related to missing documentation, bugs, logic flaws, and missing unit tests.
*   **Codebase Interaction**: Clones and periodically pulls the target GitHub repository, allowing it to list files, read file content, and execute shell commands within the repository's environment.
*   **Intelligent Decision Making**: Integrates with a configurable LLM to analyze the current repository state, past actions, and new events. It formulates "thoughts" and decides on a sequence of actions to achieve its goals, such as answering human comments, detecting TODOs in code, and prioritizing issues.
*   **Contextual Memory**: Stores and retrieves key-value pair "memories" to maintain long-term context and continuity across its operations.
*   **Event Detection**: Monitors the configured GitHub repository for new commits and updates to existing issues (e.g., new comments, state changes).
*   **Self-Management**: Can mark its current task as complete, pausing LLM inference until new external events occur, and can introduce delays in its operation.
*   **Monitoring Dashboard**: Provides a built-in web server for real-time monitoring of the agent's actions and LLM interactions.

#### Inputs

*   **GitHub Repository (API/Git)**: Codebase, commit history, and issue data (titles, bodies, comments, labels, states).
*   **LLM Responses (Internal API)**: Text generated by the configured LLM based on system and user prompts.

#### Outputs

*   **GitHub API Calls (HTTP)**: Actions such as creating, modifying, or closing issues; adding or removing labels; and commenting on issues.
*   **Local File System Operations (Filesystem/Shell)**: Reading file contents and executing shell commands within the cloned repository.
*   **LLM API Calls (HTTP)**: Prompts sent to the configured LLM for inference.
*   **Monitoring Dashboard (HTTP)**: A web interface accessible on port `5005` displaying a history of executed actions and LLM calls.

#### Configuration

The agent's behavior is configured through the following environment variables:

*   `GITHUB_PERSONAL_ACCESS_TOKEN`: Personal access token for GitHub API authentication.
*   `OPENAI_API_KEY`: API key for OpenAI LLM authentication.
*   `OPENAI_API_BASE` (Optional): Base URL for the OpenAI API (defaults to `https://api.openai.com`).
*   `OPENAI_API_MODEL` (Optional): Specific LLM model to use (defaults to `gpt-3.5-turbo`).
*   `GITHUB_REPOSITORY_OWNER`: The owner (username or organization) of the target GitHub repository.
*   `GITHUB_REPOSITORY_NAME`: The name of the target GitHub repository.
*   `GITHUB_REPOSITORY_ISSUES_BRANCH` (Optional): The Git branch where the agent will manage issues (defaults to `issues`).