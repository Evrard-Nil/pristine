### Agent Name
Pristine

### Description
Pristine is an AI agent designed to autonomously manage and maintain GitHub issues within a specified repository. It operates in a continuous loop, monitoring repository events, analyzing the current state, and making decisions to create, update, or close issues. The agent leverages Large Language Models (LLMs) for its "thinking" and "deciding" processes, and interacts with GitHub and a local Git repository clone to perform its tasks. It also provides a web-based dashboard for real-time monitoring of its activities and LLM interactions.

### Key Functions
*   **GitHub Issue Management**: Creates, retrieves, updates (title, body), closes, comments on, and manages labels (add/remove) for GitHub issues.
*   **Repository Interaction**: Clones and continuously pulls the target GitHub repository, detects new commits, and can list or read files from the local clone.
*   **LLM Integration**: Utilizes a configurable Large Language Model (e.g., GPT-3.5-turbo) to generate thoughts and decide on actions based on the current context and system prompts.
*   **Context Management**: Maintains an internal memory (key-value store) to retain important information across its operational cycles.
*   **Event Monitoring**: Continuously checks for new commits, new issues, and updates on existing issues in the GitHub repository.
*   **Self-Monitoring Dashboard**: Hosts a web server to provide a dashboard displaying a history of actions taken and LLM calls made by the agent.

### Operational Details
The agent follows a "Observe-Think-Decide-Act" loop:
1.  **Observe**: Checks for new events on the GitHub repository (commits, issues, comments, pull requests) and updates its internal state.
2.  **Think**: Uses an LLM to analyze the current context, including memories, past events, and GitHub issues, to formulate a "thought" on what actions are needed.
3.  **Decide**: Based on its "thought" and the available actions, it uses the LLM again to decide on a sequence of concrete actions to perform.
4.  **Act**: Executes the decided actions, which can involve interacting with GitHub, reading the local repository, or managing its internal memory.

The agent aims to keep issues small, actionable, and focused, avoiding duplicates and unnecessary comments. It prioritizes issues and can categorize them using labels such as `documentation`, `bug`, `enhancement`, `test`, `needs-human-input`, `ready-for-approval`, `ready-for-implementation-by-ai`, `duplicate`, `p0`, `p1`, and `p2`.

### Inputs
*   **Environment Variables**:
    *   `OPENAI_API_KEY`: Required for OpenAI API authentication.
    *   `OPENAI_API_BASE`: Optional, base URL for OpenAI API (defaults to `https://api.openai.com`).
    *   `OPENAI_API_MODEL`: Optional, specifies the LLM model (defaults to `gpt-3.5-turbo`).
    *   `GITHUB_REPOSITORY_OWNER`: Required, the GitHub username or organization owning the target repository.
    *   `GITHUB_REPOSITORY_NAME`: Required, the name of the GitHub repository to manage.
    *   `GITHUB_REPOSITORY_ISSUES_BRANCH`: Optional, the Git branch for issue management (defaults to `issues`).
*   **GitHub Repository**: Commits, issues, comments, and pull requests from the configured repository.
*   **LLM Responses**: Text generated by the configured LLM.

### Outputs
*   **GitHub (External API)**: New issues, updated issue titles/bodies, added/removed labels, comments on issues, and closed issues.
*   **Local Filesystem**: A cloned Git repository for reading file contents and detecting commits.
*   **Console (stdout)**: Logs of agent activities, thoughts, and action outputs.
*   **Web Dashboard (HTTP on port 5005)**: Provides a user interface to view action history and LLM call logs.