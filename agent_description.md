### Agent Name
Pristine

### Description
Pristine is an AI agent designed to autonomously manage and maintain GitHub issues within a specified repository. It continuously monitors for new events (like commits or issue updates), analyzes the repository's state using a Large Language Model (LLM), and takes appropriate actions to keep issues organized and up-to-date. Its primary goal is to assist in detecting and creating issues for missing documentation, bugs, and tests, as well as managing existing issues by commenting, labeling, and closing them. Pristine is an issue management agent, not a coding agent.

### Key Features
*   **GitHub Issue Management**: Creates, retrieves, updates (title, body), labels, comments on, and closes GitHub issues.
*   **Repository Interaction**: Clones and pulls the target GitHub repository, lists files, reads file content, and executes shell commands within the repository's context.
*   **LLM Integration**: Uses an external Large Language Model to process contextual information, generate thoughts, and decide on a sequence of actions.
*   **Contextual Memory**: Stores and retrieves key-value pair memories to maintain continuity and remember important information across its operational cycles.
*   **Event Monitoring**: Automatically detects new commits and updates to existing GitHub issues, triggering new rounds of analysis and action.
*   **Self-Monitoring Dashboard**: Provides a web-based dashboard to visualize its action history and LLM call logs, accessible via a local HTTP server.

### Operation Flow
The agent operates in a continuous loop:
1.  **Event Check**: Polls the configured GitHub repository for new commits and changes to issues.
2.  **Context Building**: Gathers relevant information including internal memories, open issues, past events, and recent action outputs.
3.  **Thinking**: Sends the compiled context to an LLM to generate a "thought" and a structured list of actions to perform.
4.  **Acting**: Executes the determined actions, which can involve interacting with GitHub, the local repository, or its internal memory.
5.  **Completion State**: Can be marked complete, pausing its active inference cycle until a new external event (like a new commit or issue update) occurs.

### Inputs
*   **Environment Variables**: Configuration parameters for GitHub and OpenAI API access.
*   **GitHub Repository**: Changes in commits, issues, and comments are detected by polling.
*   **LLM Responses**: Text generated by the configured Large Language Model.

### Outputs
*   **GitHub API**: Creates, updates, comments on, and closes issues (HTTP).
*   **Local Repository**: Clones and pulls repository data, executes shell commands (stdout/stderr).
*   **Web Dashboard**: Serves an HTML dashboard with action and LLM call logs (HTTP on port 5005).
*   **Console Logs**: Provides detailed operational logs and debug information (stdout).

### Configuration
The agent is configured using the following environment variables:
*   `GITHUB_PERSONAL_ACCESS_TOKEN` (Required): GitHub PAT for authentication.
*   `OPENAI_API_KEY` (Required): OpenAI API key for LLM access. `OPENAI_KEY` can be used as an alternative.
*   `OPENAI_API_BASE` (Optional): Base URL for the OpenAI API (default: `https://api.openai.com`).
*   `OPENAI_API_MODEL` (Optional): LLM model name (default: `gpt-3.5-turbo`).
*   `GITHUB_REPOSITORY_OWNER` (Required): Owner of the GitHub repository.
*   `GITHUB_REPOSITORY_NAME` (Required): Name of the GitHub repository.
*   `GITHUB_REPOSITORY_ISSUES_BRANCH` (Optional): Branch to interact with for issues (default: `issues`).