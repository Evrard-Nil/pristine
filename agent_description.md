### Agent Name
Pristine

### Description
Pristine is an autonomous AI agent designed to manage issues on a GitHub repository. It continuously monitors the repository for new commits and issue updates, leveraging a Large Language Model (LLM) to reason about the current state and decide on appropriate actions. Its primary goal is to help maintain the repository's issue health by creating, updating, labeling, commenting on, and closing issues as needed, while also detecting missing documentation, bugs, and tests. The agent operates with an internal memory to maintain context and provides a web-based dashboard for real-time monitoring of its activities.

### Key Features
*   **GitHub Issue Management:** Automatically creates, retrieves, updates (title, body), labels, comments on, and closes GitHub issues based on its reasoning.
*   **Repository Monitoring:** Detects new commits and changes to issues (new, updated, closed) by cloning and pulling the target repository.
*   **Contextual Reasoning:** Utilizes an LLM to analyze the current repository state, past events, and internal memories to formulate thoughts and decide on a sequence of actions.
*   **Internal Memory:** Stores and retrieves key-value pairs to maintain long-term context and continuity across its operations.
*   **Codebase Interaction:** Can list and read files from the cloned repository and execute shell commands within the repository's context to gather information.
*   **Monitoring Dashboard:** Provides a web interface on port `5005` to view a detailed history of executed actions and LLM calls.
*   **Action Prioritization:** Focuses on creating small, actionable issues and aims to keep the number of open issues minimal.

### Inputs
*   **Environment Variables:** Configuration for GitHub API access, OpenAI API access, and repository details.
*   **GitHub Repository Events:** New commits, new issues, updates to existing issues (including comments).
*   **LLM Responses:** Text generated by the configured Large Language Model.

### Outputs
*   **GitHub API Calls:** Creates new issues, updates existing issue titles and bodies, adds/removes labels, posts comments, and closes issues.
*   **Local Repository Interactions:** Lists files, reads file contents, and executes shell commands, with their respective outputs.
*   **LLM Requests:** Prompts sent to the OpenAI API for reasoning and action generation.
*   **Web Dashboard (HTTP):** Serves a monitoring dashboard on `http://0.0.0.0:5005` displaying action and LLM call logs.

### Configuration (Environment Variables)
The agent is configured via the following environment variables, which can be loaded from a `.env` file:
*   `GITHUB_PERSONAL_ACCESS_TOKEN` (Required): Personal access token for GitHub API authentication.
*   `OPENAI_API_KEY` (Required): API key for OpenAI LLM inference. `OPENAI_KEY` is also checked as an alternative.
*   `OPENAI_API_BASE` (Optional): Base URL for the OpenAI API (default: `https://api.openai.com`).
*   `OPENAI_API_MODEL` (Optional): Name of the OpenAI model to use (default: `gpt-3.5-turbo`).
*   `GITHUB_REPOSITORY_OWNER` (Required): GitHub username or organization owning the target repository.
*   `GITHUB_REPOSITORY_NAME` (Required): Name of the GitHub repository to manage.
*   `GITHUB_REPOSITORY_ISSUES_BRANCH` (Optional): Name of the Git branch for issue management (default: `issues`).