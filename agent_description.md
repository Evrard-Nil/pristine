### Name
Pristine

### Description
Pristine is an autonomous AI agent designed to manage and maintain GitHub issues within a specified repository. It continuously monitors the repository for changes and new events, leveraging a Large Language Model (LLM) to "think" and decide on appropriate actions. Its primary goal is to help maintain the state of issues by creating, updating, and closing them as needed, focusing on areas like documentation, bug detection, and test coverage.

### Functionality
*   **GitHub Issue Management**: Creates new issues, retrieves existing issue details, adds or removes labels, closes issues, comments on issues, and edits issue titles and bodies.
*   **Codebase Interaction**: Clones and periodically pulls the target GitHub repository, lists all files, reads file content, and executes arbitrary shell commands within the repository's context.
*   **Intelligent Decision Making**: Utilizes an LLM to analyze the current repository state, past actions, and new events to generate a "thought" process and decide on a sequence of actions to take.
*   **Context and Memory Management**: Maintains an internal memory system to store and retrieve key-value pair information, allowing it to remember important details and maintain continuity across its operations.
*   **Event Monitoring**: Automatically checks for new commits in the repository and updates to GitHub issues (including new issues or comments).
*   **Self-Monitoring Dashboard**: Provides a web-based dashboard accessible via HTTP to visualize a history of executed actions and LLM calls, including their duration and results.

### Inputs
*   **Environment Variables**: Configured via environment variables for GitHub API authentication (`GITHUB_PERSONAL_ACCESS_TOKEN`, `GITHUB_REPOSITORY_OWNER`, `GITHUB_REPOSITORY_NAME`, `GITHUB_REPOSITORY_ISSUES_BRANCH`) and OpenAI API access (`OPENAI_API_KEY`, `OPENAI_API_BASE`, `OPENAI_API_MODEL`).
*   **GitHub Repository**: Reads the repository's files and monitors its commit history.
*   **GitHub Issues**: Receives information about new, updated, or commented issues from the configured repository.
*   **LLM Responses**: Consumes text generated by the Large Language Model based on its prompts.

### Outputs
*   **GitHub Actions**: Creates, updates, comments on, labels, and closes issues on the designated GitHub repository.
*   **Shell Command Results**: Displays the standard output and error of any executed shell commands.
*   **Internal State**: Updates its internal memory and context based on its actions and observations.
*   **Web Dashboard**: Serves a monitoring dashboard over HTTP on port `5005`, displaying logs of actions performed and LLM interactions.

### Configuration
The agent is configured using the following environment variables:
*   `GITHUB_PERSONAL_ACCESS_TOKEN`: Your GitHub Personal Access Token for API authentication.
*   `OPENAI_API_KEY`: Your OpenAI API key.
*   `OPENAI_API_BASE`: (Optional) The base URL for the OpenAI API (defaults to `https://api.openai.com`).
*   `OPENAI_API_MODEL`: (Optional) The LLM model to use (defaults to `gpt-3.5-turbo`).
*   `GITHUB_REPOSITORY_OWNER`: The owner (user or organization) of the GitHub repository to manage.
*   `GITHUB_REPOSITORY_NAME`: The name of the GitHub repository to manage.
*   `GITHUB_REPOSITORY_ISSUES_BRANCH`: (Optional) The Git branch where the agent will operate for issues (defaults to `issues`).

### Monitoring
A web-based dashboard is available at `http://0.0.0.0:5005` (or the host's IP address) to provide real-time insights into the agent's operations, including a detailed history of actions taken and LLM calls made.