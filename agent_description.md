### Pristine Agent

The Pristine Agent is an autonomous AI agent designed to manage GitHub issues and monitor a specified repository. It continuously observes repository activity, uses a Large Language Model (LLM) to analyze the context, and decides on actions to maintain and improve the project's issue tracker.

**Key Features:**

*   **GitHub Issue Management:** Creates, retrieves, updates (title, body, labels), comments on, and closes GitHub issues.
*   **Repository Interaction:** Clones and pulls the target GitHub repository, lists files, reads file content, and executes shell commands within the repository's context.
*   **AI-Driven Decision Making:** Utilizes a configured LLM (e.g., OpenAI's GPT models) to analyze the current state of the repository, past events, and its internal memories to formulate thoughts and decide on a sequence of actions.
*   **Event Monitoring:** Automatically detects and reacts to new commits in the repository and updates to GitHub issues (e.g., new comments, state changes).
*   **Contextual Memory:** Stores and retrieves key-value pair memories to maintain continuity and long-term context, allowing it to remember important information and past decisions.
*   **Monitoring Dashboard:** Provides a web-based dashboard on port `5005` to display a real-time log of all actions taken and LLM calls made by the agent, offering transparency into its operations.
*   **Autonomous Operation:** Runs in a continuous loop, reacting to events and executing its decided actions. It can mark itself as complete to pause inference until new external events occur, conserving resources.

**Inputs:**

*   **GitHub Repository Events:** New commits, new issues, updates to existing issues (e.g., comments, label changes, state changes).
*   **LLM Responses:** Text generated by the configured Large Language Model based on system and user prompts.

**Outputs:**

*   **GitHub API Calls:** Creates new issues, adds comments, updates issue titles, bodies, and labels, and closes issues.
*   **Repository Interaction:** Executes shell commands within the cloned repository, potentially leading to indirect changes (though its primary role is issue management, not direct code modification).
*   **Console Output:** Logs its operational status, thoughts, and action results.
*   **Web Dashboard (HTTP on port 5005):** Serves a real-time dashboard displaying a history of actions and LLM calls.

**Configuration:**

The agent's behavior is configured via environment variables:

*   `GITHUB_PERSONAL_ACCESS_TOKEN`: Your GitHub Personal Access Token for API authentication.
*   `OPENAI_API_KEY` (or `OPENAI_KEY`): Your OpenAI API key for LLM inference.
*   `OPENAI_API_BASE`: (Optional) The base URL for the OpenAI API (defaults to `https://api.openai.com`).
*   `OPENAI_API_MODEL`: (Optional) The LLM model to use for inference (defaults to `gpt-3.5-turbo`).
*   `GITHUB_REPOSITORY_OWNER`: The owner (user or organization) of the GitHub repository to be managed.
*   `GITHUB_REPOSITORY_NAME`: The name of the GitHub repository to be managed.
*   `GITHUB_REPOSITORY_ISSUES_BRANCH`: (Optional) The specific branch the agent will operate on for issues (defaults to `issues`).